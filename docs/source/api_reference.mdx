# API Reference (Swagger)

ðŸ¤— Inference Endpoints can be used through the [UI](https://ui.endpoints.huggingface.co/endpoints) and programmatically through an API.
The API exposes [open-API specification](https://api.endpoints.huggingface.cloud/) for each available route. 

<iframe src="https://api.endpoints.huggingface.cloud/"  style='height: 60vh; width: 100%;' frameborder="0" id="iframe" frameBorder="0">Browser not compatible.</iframe>


Update May 2024: We have renamed instances and further details can be found in the [pricing documentation](https://huggingface.co/docs/inference-endpoints/pricing). For example, when using 1x A10G instance, the naming is: 
instance_type: nvidia-a10g
instance_size: x1

