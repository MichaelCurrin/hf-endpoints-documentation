# Inference Endpoints Version

Hugging Face Inference Endpoints comes with a default serving container which is used for all [supported Transformers and Sentence-Transformers tasks](/docs/inference-endpoints/supported_tasks) and for [custom inference handler](/docs/inference-endpoints/guides/custom_handler) and implement batching.
Below you will find information about the installed packages and versions used.

You can always upgrade installed packages and a custom packages by adding a `requirements.txt` file to your model repository. Read more in [Add custom Dependencies](/docs/inference-endpoints/guides/custom_dependencies).

## Installed packages & version

The installed packages are split into `general`, `CPU` & `GPU` packages. The `general` packages are installed in all containers, the `CPU` and `GPU` packages are only installed in the corresponding containers.
The Hugging Face Inference Runtime has separate versions for `PyTorch` and `TensorFlow` for `CPU` and `GPU`, which are used based on the selected `framework` when creating an Inference Endpoint. The `TensorFlow` and `PyTorch` flavors are grouped together in the list below.

### General

- `Python`: `3.11`

### CPU

- `transformers[sklearn,sentencepiece,audio,vision]`: `4.38.1`
- `diffusers`: `0.26.3`
- `accelerate`: `0.27.2`
- `sentence_transformers`: `2.4.0`
- `pandas`: `latest`
- `pytorch`: `2.2.0`
- `torchvision`: `latest`
- `tensorflow`: `latest`

### GPU

- `CUDA`: `12.3`

- `transformers[sklearn,sentencepiece,audio,vision]`: `4.38.1`
- `diffusers`: `0.26.3`
- `accelerate`: `0.27.2`
- `sentence_transformers`: `2.4.0`
- `pandas`: `latest`
- `pytorch`: `2.2.0`
- `torchvision`: `latest`
- `tensorflow`: `latest`
