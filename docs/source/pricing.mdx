# Pricing

<div class="flex md:justify-start mb-2 text-gray-400 items-center">
  <a href="https://ui.endpoints.huggingface.co/new">
    <button class="shadow-sm bg-white bg-gradient-to-br from-gray-100/20 to-gray-200/60 hover:to-gray-100/70 text-gray-700 py-1.5 rounded-lg ring-1 ring-gray-300/60 hover:ring-gray-300/30 font-semibold active:shadow-inner px-5">
      Deploy a model
    </button>
  </a>
  <span class="mx-4 ">Or</span>
  <a
    href="mailto:api-enterprise@huggingface.co"
    class="underline"
  >
    Request a quote
  </a>
</div>

Easily deploy machine learning models on dedicated infrastructure with ðŸ¤— Inference Endpoints. When you create an Endpoint, you can select the instance type to deploy and scale your model according to an hourly rate. ðŸ¤— Inference Endpoints is accessible to Hugging Face accounts with an active subscription and credit card on file. At the end of the subscription period, the user or organization account will be charged for the compute resources used while Endpoints are up and in a *running* state.

You can find the hourly pricing for all available instances for ðŸ¤— Inference Endpoints, and examples of how costs are calculated below. While the prices are shown by the hour, the actual cost is calculated by the minute.

## CPU Instances

The table below shows currently available CPU instances and their hourly pricing. If the instance type cannot be selected in the application, you need to [request a quota](mailto:api-enterprise@huggingface.co?subject=Quota%20increase%20HF%20Endpoints&body=Hello,%0D%0A%0D%0AI%20would%20like%20to%20request%20access/quota%20increase%20for%20{INSTANCE%20TYPE}%20for%20the%20following%20account%20{HF%20ACCOUNT}.) to use it.

| Provider | Instance Size | hourly rate | vCPUs | Memory | Architecture          |
| -------- | ------------- | ----------- | ----- | ------ | --------------------- |
| aws      | small         | $0.06       | 1     | 2GB    | Intel Xeon - Ice Lake |
| aws      | medium        | $0.12       | 2     | 4GB    | Intel Xeon - Ice Lake |
| aws      | large         | $0.24       | 4     | 8GB    | Intel Xeon - Ice Lake |
| aws      | xlarge        | $0.48       | 8     | 16GB   | Intel Xeon - Ice Lake |
| azure    | small         | $0.06       | 1     | 2GB    | Intel Xeon            |
| azure    | medium        | $0.12       | 2     | 4GB    | Intel Xeon            |
| azure    | large         | $0.24       | 4     | 8GB    | Intel Xeon            |
| azure    | xlarge        | $0.48       | 8     | 16GB   | Intel Xeon            |

## GPU Instances

The table below shows currently available GPU instances and their hourly pricing. If the instance type cannot be selected in the application, you need to [request a quota](mailto:api-enterprise@huggingface.co?subject=Quota%20increase%20HF%20Endpoints&body=Hello,%0D%0A%0D%0AI%20would%20like%20to%20request%20access/quota%20increase%20for%20{INSTANCE%20TYPE}%20for%20the%20following%20account%20{HF%20ACCOUNT}.) to use it.

| Provider | Instance Size | hourly rate | GPUs | Memory | Architecture |
| -------- | ------------- | ----------- | ---- | ------ | ------------ |
| aws      | small         | $0.60       | 1    | 14GB   | NVIDIA T4    |
| aws      | medium        | $1.30       | 1    | 24GB   | NVIDIA A10G  |
| aws      | large         | $4.50       | 4    | 56GB   | NVIDIA T4    |
| aws      | xlarge        | $6.50       | 1    | 80GB   | NVIDIA A100  |
| aws      | xxlarge       | $7.00       | 4    | 96GB   | NVIDIA A10G  |
| aws      | xxxlarge      | $45.00      | 8    | 640GB  | NVIDIA A100  |

The following example pricing scenarios demonstrate how costs are calculated. You can find the hourly rate for all instance types and sizes in the tables above. Use the following formula to calculate the costs:

```
instance hourly rate * ((hours * # min replica) + (scale-up hrs * # additional replicas))
```

If you are using a **medium CPU by AWS without any autoscaling** for **1 hr**, the cost would be:

```
cost = $0.12/hr * ((1 hr * 1 replica) + (0 hrs * 0 additional replicas))
$0.12/hr
```

| Hourly cost | Monthly cost |
|-------------|--------------|
| $0.12       | $87.6        |

Now imagine you want to use a slightly larger instance, like a **large CPU by Azure and a maximum of 3 replicas**. Again, you're only using this CPU for **1 hour**, but a spike in traffic scales the Endpoint from **1 to 3 replicas** for half a hour:

```
cost = $0.24/hr * ((1 hr * 1 replica) + (0.5 hrs * 2 additional replicas))
$1.24
```

| Hourly cost | Monthly cost |
|-------------|--------------|
| $1.24       | $905.2       |

But now you want something more powerful, so you decide to use a **large GPU by AWS and a maximum of 5 replicas**. This time, you'll use the GPU for **3 hours** and you get a spike in traffic every **0.25** hours which scales the Endpoint from **1 to 4 replicas**. You didn't need to scale to the maximum number of replicas, so you're only charged for what you actually use.

```
cost = $6.50/hr * ((3 hrs * 1 replica) + (0.25 hrs * 3 additional replicas))
cost = $24.375
```

| Hourly cost | Monthly cost |
|-------------|--------------|
| $24.375     | $17793.75    |
